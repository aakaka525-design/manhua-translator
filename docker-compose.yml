services:
  api:
    platform: linux/amd64
    build:
      context: .
      dockerfile: docker/Dockerfile.api
      args:
        INSTALL_LAMA: "0"
    env_file:
      - .env
    environment:
      AUTO_SETUP_MODELS: "on"
      MODEL_WARMUP_TIMEOUT: "300"
      OCR_WARMUP_LANGS: "korean"
      LAMA_DEVICE: "cpu"
      FLAGS_use_mkldnn: "0"
      FLAGS_use_pir_api: "0"
      PADDLE_PDX_DISABLE_MODEL_SOURCE_CHECK: "True"
    volumes:
      - ./data:/app/data
      - ./output:/app/output
      - ./logs:/app/logs
      - ./models:/root/.paddlex
    ports:
      - "8000:8000"
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/api/v1/system/models', timeout=5).read()"]
      interval: 10s
      timeout: 5s
      retries: 12

  web:
    platform: linux/amd64
    build:
      context: .
      dockerfile: docker/Dockerfile.web
    depends_on:
      api:
        condition: service_healthy
    ports:
      - "80:80"
